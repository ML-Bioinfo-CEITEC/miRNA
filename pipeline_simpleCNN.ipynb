{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47589047-c01d-4f67-ba6e-9769e0d78a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Using cached gdown-4.7.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: filelock in /home/jovyan/my-conda-envs/deepExpTorch2/lib/python3.8/site-packages (from gdown) (3.12.4)\n",
      "Requirement already satisfied: requests[socks] in /home/jovyan/my-conda-envs/deepExpTorch2/lib/python3.8/site-packages (from gdown) (2.31.0)\n",
      "Requirement already satisfied: six in /home/jovyan/my-conda-envs/deepExpTorch2/lib/python3.8/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /home/jovyan/my-conda-envs/deepExpTorch2/lib/python3.8/site-packages (from gdown) (4.66.1)\n",
      "Collecting beautifulsoup4 (from gdown)\n",
      "  Using cached beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->gdown)\n",
      "  Obtaining dependency information for soupsieve>1.2 from https://files.pythonhosted.org/packages/4c/f3/038b302fdfbe3be7da016777069f26ceefe11a681055ea1f7817546508e3/soupsieve-2.5-py3-none-any.whl.metadata\n",
      "  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jovyan/my-conda-envs/deepExpTorch2/lib/python3.8/site-packages (from requests[socks]->gdown) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jovyan/my-conda-envs/deepExpTorch2/lib/python3.8/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jovyan/my-conda-envs/deepExpTorch2/lib/python3.8/site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jovyan/my-conda-envs/deepExpTorch2/lib/python3.8/site-packages (from requests[socks]->gdown) (2023.7.22)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/jovyan/my-conda-envs/deepExpTorch2/lib/python3.8/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4, gdown\n",
      "Successfully installed beautifulsoup4-4.12.2 gdown-4.7.1 soupsieve-2.5\n"
     ]
    }
   ],
   "source": [
    "# Run these lines only the first time you run this notebook\n",
    "\n",
    "# !wget https://raw.githubusercontent.com/ML-Bioinfo-CEITEC/miRBind/graphs/Datasets/evaluation_set_1_1_CLASH2013_paper.tsv\n",
    "# !pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3a3580f-b686-4f37-a676-6b8c01da11db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1ayyD1w6SHzLS8638eoBzUX3OMq4cxSUx\n",
      "From (redirected): https://drive.google.com/uc?id=1ayyD1w6SHzLS8638eoBzUX3OMq4cxSUx&confirm=t&uuid=3c1ed14d-0a5c-45db-bc38-c8a0e05e3548\n",
      "To: /home/jovyan/miRNA/miRNA/TESTexplainability_scores_hsa-miR-106b-5p.json\n",
      "100%|██████████| 1.99G/1.99G [00:10<00:00, 183MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'TESTexplainability_scores_hsa-miR-106b-5p.json'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run these lines only the first time you run this notebook\n",
    "\n",
    "# import gdown\n",
    "\n",
    "# url = \"https://drive.google.com/file/d/1ayyD1w6SHzLS8638eoBzUX3OMq4cxSUx/view?usp=sharing\"\n",
    "# output = \"explainability_scores_hsa-miR-106b-5p.json\"\n",
    "# gdown.download(url=url, output=output, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc91c6ec-bc01-4351-bedc-43912095082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a68e5d64-5a9d-438f-9ee1-5b43bb86dd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the %autoreload extension using the %load_ext magic command\n",
    "#Then, we set the %autoreload magic command to 2, which means that modules will be reloaded every time a cell is executed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ee7a08c-06f8-42a7-8ae1-ec282134b3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import CometLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fcf158-3193-4f16-9cfd-21c5b3d460b9",
   "metadata": {},
   "source": [
    "### Get the FC scores from Bartel files   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "599905fb-5dfe-41b0-bef7-3cc1b8a5945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mirna_FCs = pd.read_csv('modules/evaluation/mirna_fcs.csv',index_col=0, header=0, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f5038ec-67cc-44bc-b9fa-cb223a6333db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gene symbol',\n",
       " 'hsa-miR-16-5p',\n",
       " 'hsa-miR-106b-5p',\n",
       " 'hsa-miR-200a-3p',\n",
       " 'hsa-miR-200b-3p',\n",
       " 'hsa-miR-215-5p',\n",
       " 'hsa-let-7c-5p',\n",
       " 'hsa-miR-103a-3p']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mirna_FCs.columns.values\n",
    "list(mirna_FCs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927cde65-ccd2-44c0-ab6f-646c45815b40",
   "metadata": {
    "tags": []
   },
   "source": [
    "### All miRNAs ready for later --- for now we skip this section and use only one RNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71f2beb8-4d53-4371-b30d-011eb6997b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import rna_to_dna\n",
    "\n",
    "# mirna_sequences = ['UAGCAGCACGUAAAUAUUGGCG', 'UAAAGUGCUGACAGUGCAGAU', 'UAACACUGUCUGGUAACGAUGU', 'UAAUACUGCCUGGUAAUGAUGA', 'AUGACCUAUGAAUUGACAGAC', 'UGAGGUAGUAGGUUGUAUGGUU', 'AGCAGCAUUGUACAGGGCUAUGA']\n",
    "# mirna_sequences = [rna_to_dna(x) for x in mirna_sequences]\n",
    "# print(mirna_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7614763c-85aa-4787-b816-a1dd80e86b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# miRNA_names = ['hsa-miR-16-5p', 'hsa-miR-106b-5p', 'hsa-miR-200a-3p', 'hsa-miR-200b-3p', 'hsa-miR-215-5p', 'hsa-let-7c-5p', 'hsa-miR-103a-3p']\n",
    "# miRNA_name_to_seq = {}\n",
    "# for i in range(len(miRNA_names)):\n",
    "#     miRNA_name_to_seq[miRNA_names[i]] = mirna_sequences[i]\n",
    "# miRNA_name_to_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec221ad-cf51-4a70-9cb9-7db63d6ae602",
   "metadata": {},
   "source": [
    "### Set the miRNA of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6b93ccd-94e5-4ba7-a000-60ce97af32ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mirna_name = 'hsa-miR-106b-5p'\n",
    "mirna_seq = 'TAAAGTGCTGACAGTGCAGAT'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9702d170-1baf-49bd-89be-b5ebd7988c57",
   "metadata": {},
   "source": [
    "### Binding sites processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e339d1ac-1d00-44c0-bd76-438dae5f07be",
   "metadata": {},
   "source": [
    "#### Collect binding sites "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03275a7f-cbb7-4c97-8bf3-c753db4c44a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collect_binding_sites import collect_binding_sites\n",
    "\n",
    "load_scores_path = \"explainability_scores_{}.json\".format(mirna_name)\n",
    "binding_sites = collect_binding_sites(load_scores_path, mirna_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b345177e-56a3-4ab7-923c-d28f6bc019bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([2340, 4090]), array([2390, 4140]), array([50, 50])),\n",
       " (array([ 450, 1230, 2010, 2560, 2650, 5400]),\n",
       "  array([ 500, 1280, 2060, 2640, 2710, 5450]),\n",
       "  array([50, 50, 50, 80, 60, 50]))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each item of binding_sites contains a triplet of arrays: ([starts],[ends],[lengths])\n",
    "# 1st item in [starts] coresponds to 1st item in [ends] and [lengths] aswell, 2nd start to 2nd end and length, and so on\n",
    "binding_sites[6:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a978d3-7ad7-4b6f-b768-d71e98259a5e",
   "metadata": {},
   "source": [
    "#### Transform binding sites into input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80ab627b-e4df-4a9d-801e-d9c8f933a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extraction import count_statistics, normalize_statistics, FEATURES, FEATURE_NAMES\n",
    "\n",
    "input_data, input_data_genes, transcripts_with_no_bs = count_statistics(binding_sites, load_scores_path, mirna_seq)\n",
    "\n",
    "input_data_normalized = normalize_statistics(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbb3f10-dae8-42e8-ae90-0f84991e2c9c",
   "metadata": {},
   "source": [
    "#### Padding input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d5d32a-b758-446b-b9f1-d0192b1b1d0b",
   "metadata": {},
   "source": [
    "##### Padding to 10 binding sites per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eec0b84c-52b2-4af3-a69f-94a9fa79cfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pad_input_data import pad_features\n",
    "\n",
    "padded_data_tensor = pad_features(input_data_normalized, pad_to_length = (len(FEATURES) * 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9148dc8e-c786-40c1-9d0d-d4d1aed4f294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25629,\n",
       " torch.Size([40]),\n",
       " tensor([0.0015, 0.0022, 0.0086, 0.0486, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000], dtype=torch.float64))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(padded_data_tensor), padded_data_tensor[0].size(), padded_data_tensor[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014835ef-4809-43a4-b046-b68e60d85342",
   "metadata": {},
   "source": [
    "### Get labels & Remove genes without fold change from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2267de3b-8ac1-44d1-85ed-ee73ab0a3165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is  20167 genes for which we do not have fold change because they are not in the Bartel table, out of total 25629 and 171 nan valued genes in FC table\n"
     ]
    }
   ],
   "source": [
    "from utils import get_labels\n",
    "\n",
    "input_labels, padded_data_tensor, input_data_genes_filtered = get_labels(mirna_name, padded_data_tensor, input_data_genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c5c7cd-b8f4-4a96-b0a2-d85c7f650d9c",
   "metadata": {},
   "source": [
    "### Split train/validation/test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fed8336-f9d8-4621-a337-05144c37711b",
   "metadata": {},
   "source": [
    "#### Create test set based on what genes we can compare on with Bartel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bf90f4d-da8f-4f34-a4d6-f99ae079ebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# genes we can compare with Bartel are in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "428ed50e-5751-4356-b6e2-dbbef112d885",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import split_train_test_bartel\n",
    "\n",
    "x_train, y_train, x_val, y_val, x_test, y_test, gene_names_train, gene_names_val, gene_names_test = split_train_test_bartel(\n",
    "    padded_data_tensor, \n",
    "    input_labels, \n",
    "    input_data_genes_filtered, \n",
    "    mirna_FCs,\n",
    "    mirna_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5765ca50-bb7b-4883-81be-a311badc053b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4239 472 580\n",
      "4239 472 580\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train), len(y_val), len(y_test))\n",
    "print(len(gene_names_train), len(gene_names_val), len(gene_names_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba214ef8-beb2-4b52-bf81-8902323d1394",
   "metadata": {},
   "source": [
    "### Create pytorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58999cb3-beec-4211-990c-73e5a34aa775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_train_dataloader, get_val_dataloader, get_test_dataloader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_loader = get_train_dataloader(x_train, y_train, BATCH_SIZE)\n",
    "val_loader = get_val_dataloader(x_val, y_val, BATCH_SIZE)\n",
    "test_loader = get_test_dataloader(x_test, y_test, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9113479-565b-43c8-be73-7144c537d27e",
   "metadata": {},
   "source": [
    "### comet.ml for logging online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e10f5f5d-b89e-474c-afd5-db117f2a3339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CometLogger will be initialized in online mode\n"
     ]
    }
   ],
   "source": [
    "comet_logger = CometLogger(\n",
    "    api_key=\"EpKIINrla6U4B4LJhd9Sv4i0b\",\n",
    "    project_name=\"mirna\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cac69c79-3736-475d-8726-ed202be8ca88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type              | Params\n",
      "---------------------------------------------------\n",
      "0 | architecture | Sequential        | 350   \n",
      "1 | ce           | MSELoss           | 0     \n",
      "2 | mae          | MeanAbsoluteError | 0     \n",
      "3 | mse          | MeanSquaredError  | 0     \n",
      "4 | r2           | R2Score           | 0     \n",
      "---------------------------------------------------\n",
      "350       Trainable params\n",
      "0         Non-trainable params\n",
      "350       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m You are trying to log string value as a metric. This is not recommended.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/davidcechak/mirna/20acf22e40e44a5e9807e06cd5e51741\n",
      "\n",
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/davidcechak/mirna/20acf22e40e44a5e9807e06cd5e51741\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train mae [3]      : (0.10372022539377213, 0.14751671254634857)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train mse [3]      : (0.021027671173214912, 0.039156679064035416)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train r2 [3]       : (-1.0286518335342407, -0.039192914962768555)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train rmse [3]     : (0.14200980961322784, 0.18283899128437042)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_acc_cum [7]  : (0.010161448270082474, 0.03638302534818649)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss [3]     : (0.021027671173214912, 0.039156679064035416)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss_cum [7] : (0.010161448270082474, 0.03638302534818649)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     valid mae [3]      : (0.10981428623199463, 0.11102699488401413)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     valid mse [3]      : (0.022400835528969765, 0.022709520533680916)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     valid r2 [3]       : (-0.03651369735598564, -0.022610967978835106)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     valid rmse [3]     : (0.14740747213363647, 0.14838676154613495)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     valid_loss [3]     : (0.022400835528969765, 0.022709520533680916)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Created from : pytorch-lightning\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-environment-definition : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-info                   : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-specification          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed)     : 1 (66.11 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 1 metrics, params and output messages\n"
     ]
    }
   ],
   "source": [
    "from model import Small_CNN\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from IPython.utils import io\n",
    "\n",
    "\n",
    "model = Small_CNN(pooling='att')\n",
    "# trainer = Trainer(max_epochs=1, gpus=1)  # Use GPU if available, train for X epochs\n",
    "trainer = Trainer(logger=comet_logger, max_epochs=3)  # Use GPU if available, train for X epochs\n",
    "\n",
    "# capture_output to have a cleaner notebook\n",
    "# you can follow the training at the  https://www.comet.com/davidcechak/mirna/  see log of this cell\n",
    "with io.capture_output() as captured:\n",
    "    trainer.fit(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bd8bb4-ed62-43fd-92fc-3e993318c1bf",
   "metadata": {},
   "source": [
    "#### TODO save the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182e188b-6c6b-4598-b998-5eb735c728b7",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80180932-0a1f-4f0d-9528-4141c3240e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/my-conda-envs/deepExpTorch2/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 128 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   0%|          | 0/19 [00:00<?, ?it/s]torch.Size([32, 1, 40]) test_step\n",
      "Testing DataLoader 0:   5%|▌         | 1/19 [00:00<00:00, 344.30it/s]torch.Size([32, 1, 40]) test_step\n",
      "Testing DataLoader 0:  11%|█         | 2/19 [00:00<00:00, 389.64it/s]torch.Size([32, 1, 40]) test_step\n",
      "Testing DataLoader 0:  16%|█▌        | 3/19 [00:00<00:00, 414.99it/s]torch.Size([32, 1, 40]) test_step\n",
      "Testing DataLoader 0:  21%|██        | 4/19 [00:00<00:00, 427.83it/s]torch.Size([32, 1, 40]) test_step\n",
      "Testing DataLoader 0:  26%|██▋       | 5/19 [00:00<00:00, 326.78it/s]torch.Size([32, 1, 40]) test_step\n",
      "Testing DataLoader 0:  32%|███▏      | 6/19 [00:00<00:00, 344.52it/s]torch.Size([32, 1, 40]) test_step\n",
      "Testing DataLoader 0:  37%|███▋      | 7/19 [00:00<00:00, 358.92it/s]torch.Size([32, 1, 40]) test_step\n",
      "Testing DataLoader 0:  42%|████▏     | 8/19 [00:00<00:00, 355.95it/s]torch.Size([32, 1, 40]) test_step\n",
      "Testing DataLoader 0:  47%|████▋     | 9/19 [00:00<00:00, 366.50it/s]torch.Size([32, 1, 40]) test_step\n",
      "Testing DataLoader 0:  53%|█████▎    | 10/19 [00:00<00:00, 367.87it/s]torch.Size([32, 1, 40]) test_step\n",
      "Testing DataLoader 0:  58%|█████▊    | 11/19 [00:00<00:00, 375.71it/s]torch.Size([32, 1, 40]) test_step\n",
      "Testing DataLoader 0:  63%|██████▎   | 12/19 [00:00<00:00, 378.19it/s]torch.Size([32, 1, 40]) test_step\n",
      "Testing DataLoader 0:  68%|██████▊   | 13/19 [00:00<00:00, 383.35it/s]torch.Size([32, 1, 40]) test_step\n",
      "Testing DataLoader 0:  74%|███████▎  | 14/19 [00:00<00:00, 388.59it/s]torch.Size([32, 1, 40]) test_step\n",
      "Testing DataLoader 0:  79%|███████▉  | 15/19 [00:00<00:00, 393.61it/s]torch.Size([32, 1, 40]) test_step\n",
      "Testing DataLoader 0:  84%|████████▍ | 16/19 [00:00<00:00, 398.03it/s]torch.Size([32, 1, 40]) test_step\n",
      "Testing DataLoader 0:  89%|████████▉ | 17/19 [00:00<00:00, 368.12it/s]torch.Size([32, 1, 40]) test_step\n",
      "Testing DataLoader 0:  95%|█████████▍| 18/19 [00:00<00:00, 372.67it/s]torch.Size([4, 1, 40]) test_step\n",
      "Testing DataLoader 0: 100%|██████████| 19/19 [00:00<00:00, 377.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/davidcechak/mirna/20acf22e40e44a5e9807e06cd5e51741\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 19/19 [00:01<00:00, 13.37it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">            mae            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.22644585371017456    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">            mse            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0899789035320282     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">            r2             </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    -0.9302238821983337    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           rmse            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2940700352191925     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0899789035320282     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m           mae           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.22644585371017456   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m           mse           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0899789035320282    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m           r2            \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   -0.9302238821983337   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          rmse           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2940700352191925    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0899789035320282    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml ExistingExperiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/davidcechak/mirna/20acf22e40e44a5e9807e06cd5e51741\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mae       : 0.22644585371017456\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mse       : 0.0899789035320282\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     r2        : -0.9302238821983337\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rmse      : 0.2940700352191925\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_loss : 0.0899789035320282\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Created from : pytorch-lightning\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 22 metrics, params and output messages\n"
     ]
    }
   ],
   "source": [
    "result = trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41a9f2e-d917-4552-939b-0af0dd9ca06c",
   "metadata": {},
   "source": [
    "#### TODO fix R^2, should be <0,1>, not negative https://torchmetrics.readthedocs.io/en/stable/regression/r2_score.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7231458b-a87f-4c80-987a-bec0db132a57",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd1487ff-06bf-42e7-8821-8df09d7071e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('PSEN1', 0.023890972137451172), ('LAMA3', 0.023361869156360626)]\n"
     ]
    }
   ],
   "source": [
    "from dataset import predict\n",
    "\n",
    "gene_to_predictions, predictions = predict(model, x_test, gene_names_test)\n",
    "print(list(gene_to_predictions.items())[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19320833-dbd3-4aa2-b3ee-e89f5cee6745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model metrics: \n",
      "[{'test_loss': 0.0899789035320282, 'mse': 0.0899789035320282, 'mae': 0.22644585371017456, 'r2': -0.9302238821983337, 'rmse': 0.2940700352191925, 'corr': 0.013370234198257154}]\n",
      "corr 0.013370234198257154\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "results = {}\n",
    "results['model'] = result[0]\n",
    "\n",
    "# computes correlation of model predictions and true labels\n",
    "model_corr = np.corrcoef(predictions, y_test)[0][1]\n",
    "results['model']['corr'] = model_corr\n",
    "\n",
    "print('Model metrics: ')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9448a3dc-749b-4c3b-a3f1-77de778e2637",
   "metadata": {},
   "source": [
    "### Compare with baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7c102f1-9574-4b23-ab8f-921838f5ac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_baseline_metrics(all_results, baseline_name):\n",
    "    print('Baseline metrics: ')\n",
    "    print(all_results[baseline_name])\n",
    "    print('\\n MAE: Our prediction is better by ', all_results[baseline_name]['mae'] - all_results['model']['mae'], ' our MAE: ', all_results['model']['mae'], '; baseline MAE: ', all_results[baseline_name]['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffebccc-42f5-4fd2-a42a-d4f541ab5a34",
   "metadata": {},
   "source": [
    "#### Baseline #1 mean of the training dataset labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa08e269-9540-4c43-9234-bdf0750bac2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline metrics: \n",
      "{'mse': 0.09032236039638519, 'mae': 0.2273177057504654, 'r2': -0.6783593893051147, 'rmse': 0.30053678154945374, 'corr': None}\n",
      "\n",
      " MAE: Our prediction is better by  0.0008718520402908325  our MAE:  0.22644585371017456 ; baseline MAE:  0.2273177057504654\n"
     ]
    }
   ],
   "source": [
    "from utils import get_baseline_metrics\n",
    "from statistics import mean\n",
    "\n",
    "# Baseline: mean of the training dataset labels\n",
    "baseline_name = 'mean_baseline'\n",
    "train_x_mean = mean(y_train)\n",
    "baseline_mean = np.full((len(y_test),), train_x_mean)\n",
    "results[baseline_name] = get_baseline_metrics(baseline_mean, y_test)\n",
    "\n",
    "print_baseline_metrics(results, baseline_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547b067a-140d-419b-a1a8-ed9931f69d0d",
   "metadata": {},
   "source": [
    "#### Baseline #2 random in range(min_y_tran, max_y_train) of the training dataset labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "843e26ae-35ea-4720-aa83-d3a5d36b4e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min, max : -0.983 0.961\n",
      "Baseline metrics: \n",
      "{'mse': 0.4174586534500122, 'mae': 0.5432375073432922, 'r2': -6.757167339324951, 'rmse': 0.6461104154586792, 'corr': 0.01458594582629234}\n",
      "\n",
      " MAE: Our prediction is better by  0.3167916536331177  our MAE:  0.22644585371017456 ; baseline MAE:  0.5432375073432922\n"
     ]
    }
   ],
   "source": [
    "# Baseline: for each test sample returns a random item in range(min_y_tran, max_y_train) of the training dataset labels\n",
    "baseline_name = 'mean_rnd'\n",
    "baseline_max = max(y_train)\n",
    "baseline_min = min(y_train)\n",
    "np.random.seed(42)\n",
    "print('min, max :', baseline_min, baseline_max)\n",
    "baseline_rnd = np.random.uniform(baseline_min, baseline_max, [len(y_test)])\n",
    "results[baseline_name] = get_baseline_metrics(baseline_rnd, y_test)\n",
    "\n",
    "print_baseline_metrics(results, baseline_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3790bedf-c4fc-4758-8271-ab519bb59b08",
   "metadata": {},
   "source": [
    "### Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5aa6a40f-74fa-459a-806b-80fc35db3ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('results.json', 'w') as fp:\n",
    "    json.dump(results, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ec0eac-4406-4f10-88ba-a647f7f20fdb",
   "metadata": {},
   "source": [
    "### Compare with Bartel - correlation and top predictions plot (i.e. genes with highest predicted FC plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f276c4d-f187-427b-96ce-668fb1ce0b60",
   "metadata": {},
   "source": [
    "### TODO metrics and comparison plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5bb0f83-2405-4994-ba48-1c2672db6470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda list --explicit > spec-file.txt\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67a016b-acac-452c-a52a-6ccd7934d9da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepExpTorch2]",
   "language": "python",
   "name": "conda-env-deepExpTorch2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
